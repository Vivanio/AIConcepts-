{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages ##\n",
    "\n",
    "First, you need to import all the packages that you will need during this assignment. \n",
    "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [pandas](pandas.pydata.org/) is an important package for Python data analysis.\n",
    "- [jdc](https://alexhagen.github.io/jdc/) : Jupyter magic that allows defining classes over multiple jupyter notebook cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Required Methods ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - How to display the column names of a given dataset ###\n",
    "- Pandas [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n",
    "- Pandas [pandas.DataFrame.columns](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.columns.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "2  7  8  9\n"
     ]
    }
   ],
   "source": [
    "# Define a DataFrame object\n",
    "df_sample = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "                   columns=['a', 'b', 'c'])\n",
    "\n",
    "# print the content of the DataFrame\n",
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['a', 'b', 'c'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the dataset\n",
    "print(df_sample.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graded Excercise #### \n",
    "Print out the column names of the training set that will be used in this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['wesley', 'romulan', 'poetry', 'honor', 'tea', 'barclay', 'class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Will be graded\n",
    "# Will be graded\n",
    "\n",
    "# Load the training data that we will use in this assignment\n",
    "df_train = pd.read_csv('train.csv')\n",
    "\n",
    "# Print the column names of the training data\n",
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "# Replace ??? with the correct code\n",
    "print(df_train.columns)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - How to determine the unique values in a given array ###\n",
    "- [numpy.unique](https://numpy.org/doc/stable/reference/generated/numpy.unique.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the unique values in an array\n",
    "arr = np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 4])\n",
    "np.unique(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4]), array([4, 3, 2, 1], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return both the unique values and the count of each value\n",
    "np.unique(arr, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values are [1 2 3 4]\n",
      "Corresponding counts are [4 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "# You can store the uniuqe values and their counts in variables\n",
    "values, counts = np.unique(arr, return_counts=True)\n",
    "print(\"Unique values are\", values)\n",
    "print(\"Corresponding counts are\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graded Excercise #### \n",
    "Print out the unique values in the column of \"wesley\" and their corresponding counts\n",
    "- hint: the \"wesley\" column can be obtained by using df['wesley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'barclay' are [0 1]\n",
      "Corresponding counts are [417 383]\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "values, counts = np.unique(df_train['barclay'], return_counts=True)\n",
    "### END CODE HERE ###\n",
    "print(\"Unique values in 'barclay' are\", values)\n",
    "print(\"Corresponding counts are\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - DataFrame.where ###\n",
    "-[DataFrame.where](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.where.html)\n",
    "- Identify a subset based on certain conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c\n",
       "0  NaN  NaN  NaN\n",
       "1  4.0  5.0  6.0\n",
       "2  7.0  8.0  9.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For df_sample above, we want to find out items whose a >= 4\n",
    "df_sample.where(df_sample['a'] >= 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, if items are evaluated to be false, they are replaced by \"NaN\".\n",
    "- [DataFrame.dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)\n",
    "- It can drop the \"NaN\" rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c\n",
       "1  4.0  5.0  6.0\n",
       "2  7.0  8.0  9.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.where(df_sample['a'] >= 4).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4.0\n",
       "2    7.0\n",
       "Name: a, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NaN and return a specific column\n",
    "df_sample.where(df_sample['a'] >= 4).dropna()['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graded Exercise ####\n",
    "- Return the list of items where tea=1 in our training set\n",
    "- Only show the \"class\" column in your result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      0.0\n",
       "7      1.0\n",
       "9      1.0\n",
       "10     1.0\n",
       "15     0.0\n",
       "      ... \n",
       "788    0.0\n",
       "792    0.0\n",
       "793    0.0\n",
       "797    1.0\n",
       "799    0.0\n",
       "Name: class, Length: 403, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "# Replace ??? with the correct code\n",
    "df_train.where(df_train['tea'] == 1).dropna()['class']\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Fundamentals in Decision Tree ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Entropy ###\n",
    "- As usual, we will define a class named \"Decision_Tree\"\n",
    "- We will implement entropy function:\n",
    "$$ H = -\\sum_{i=1}^{n} P_{i} * \\log_{2}P_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Tree():\n",
    "    def entropy(self, column):\n",
    "        \"\"\"\n",
    "        Calculate the entropy of a given data column.\n",
    "        column: the data column\n",
    "        \"\"\"\n",
    "        \n",
    "        # the list that will contain every -pi * log(pi)\n",
    "        ent_list = []\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        # Determine the unique values in the column and their corresponding counts of each unique value\n",
    "        values, counts =  np.unique(column, return_counts=True)\n",
    "        \n",
    "        # The number of disctint values\n",
    "        num_distinct_values = len(values)\n",
    "        # the total number of items in the column\n",
    "        total_items_in_column = len(column)\n",
    "        \n",
    "        for i in range(num_distinct_values):\n",
    "            # calculate the probability pi for the ith value \n",
    "            p_i = counts[i]/np.sum(counts)\n",
    "            # calculate -pi * log(pi)\n",
    "            ent_i =  -(0-1) * p_i * np.log2(p_i)\n",
    "            #put the result into the list\n",
    "            ent_list.append(ent_i)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return np.sum(ent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Information Gain ###\n",
    "$$ IG(S|a) = entropy(S) - \\sum_{v \\in values(a)} \\frac {|S_{v}|} {|S|} * entropy(S_{v})$$\n",
    "where\n",
    "- $IG(S|a)$ means the information gain if we split data S using attribute a\n",
    "- $|S_{v}|$ means the number of items with $a = v$\n",
    "- $|S|$ means the total number of items in S\n",
    "- $\\frac {|S_{v}|} {|S|}$ is the probability of $ a = v $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Decision_Tree\n",
    "def Infomation_Gain(self, S, entropy_before_splitting, a, class_name = \"class\"):\n",
    "    \"\"\"\n",
    "    Calculate the information gain of a dataset. This function takes four parameters:\n",
    "    1. S: the overall dataset (See the equation above)\n",
    "    2. entropy_before_splitting: the entropy before splitting\n",
    "    3. a: the attribute that we will use to split the data (See the equation above)\n",
    "    4. class_name = the class that the set of data is classified as\n",
    "    \"\"\"    \n",
    "    # the list that will contain the weighted entropy of each child, i.e., Pv * Hv, \n",
    "    #       where Pv is the probability of being in the child node v, and\n",
    "    #       Hv is the entropy of child node v: entropy(Sv).\n",
    "    H_list = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    #determine the unique values and their corresponding counts for the split attribute \n",
    "    unique_vals, counts= np.unique(S[a], return_counts=True)\n",
    "    \n",
    "    #calculate the total number of items in S\n",
    "    total_S = len(S)\n",
    "    #Calculate the total number of unnique values with regard to attribute a\n",
    "    total_Sv = len(unique_vals)\n",
    "    \n",
    "    for i in range(total_Sv):\n",
    "        # the probablity of being in the ith child node\n",
    "        P_i = counts[i]/np.sum(counts)\n",
    "        # the value v of the ith child\n",
    "        v = counts[i]/np.sum(counts)\n",
    "        # the subset Sv, where a = v\n",
    "        # hint: use DataFrame.where and only return the \"class\" column\n",
    "        S_v = S.where(S[a] == v).dropna()[class_name]\n",
    "        # the entropy of child node Sv\n",
    "        H_i =  self.entropy(S_v)\n",
    "        # put P_i * H_i into the H_list \n",
    "        H_list.append(P_i * H_i)\n",
    "    \n",
    "    # calculate the conditional entropy based on H_list\n",
    "    conditional_entropy =  np.sum(H_list)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #Calculate the information gain\n",
    "    Information_Gain = entropy_before_splitting - conditional_entropy\n",
    "    return Information_Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Experiment ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy before splitting is  -0.9965700521510767\n",
      "Information gain for tea is  -0.9965700521510767\n"
     ]
    }
   ],
   "source": [
    "DT = Decision_Tree()\n",
    "\n",
    "### START CODE HERE ###\n",
    "# Data set has been obtained in df_train above\n",
    "# Calculate the entropy before splitting based on df_train\n",
    "entropy_before_split = DT.entropy(df_train)\n",
    "print(\"Entropy before splitting is \", entropy_before_split)\n",
    "\n",
    "#calcuate the information gain for attribute \"ig\"\n",
    "ig = DT.Infomation_Gain(df_train, entropy_before_split, 'barclay')\n",
    "print(\"Information gain for tea is \", ig)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
